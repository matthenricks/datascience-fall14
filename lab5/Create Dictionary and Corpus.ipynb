{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from unidecode import unidecode\n",
      "import re\n",
      "\n",
      "from gensim import corpora\n",
      "from nltk.stem.porter import *\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.tokenize import WordPunctTokenizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up the infrastructure to clean the text\n",
      "stopset = set(stopwords.words('english'))\n",
      "stemmer = PorterStemmer()\n",
      "def cleanText(column):\n",
      "    tokens = WordPunctTokenizer().tokenize(column)\n",
      "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 5]\n",
      "    final = [stemmer.stem(word) for word in clean]\n",
      "    return final"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up the dictionary\n",
      "dictionary = corpora.Dictionary()\n",
      "def addToDictionary(cleaned):\n",
      "    dictionary.add_documents(cleaned)\n",
      "\n",
      "def saveDictionary(filepath):\n",
      "    print dictionary\n",
      "    dictionary.save(filepath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Switch to our working directory and set up our input and out put paths,\n",
      "# as well as our settings and training file locations\n",
      "input_file = 'products.csv'\n",
      "\n",
      "with open(input_file) as f:\n",
      "    reader = csv.DictReader(f)\t\n",
      "    for row in reader:\n",
      "        column = unidecode(row['description'])\n",
      "        column = re.sub('  +', ' ', column)\n",
      "        column = re.sub('\\n', ' ', column)\n",
      "        column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
      "        \n",
      "        if column != \"\":\n",
      "            myString = \"\"\n",
      "            for x in cleanText(column):\n",
      "                myString += x + ' '\n",
      "            addToDictionary([myString.split()])\n",
      "            \n",
      "    saveDictionary('dictionary.mm') "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(7677 unique tokens: [u'yellow', u'interchang', u'autoformat', u'wondrou', u'authorit']...)\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(input_file) as f:\n",
      "    reader = csv.DictReader(f)\t\n",
      "    corpus = []\n",
      "    for row in reader:\n",
      "        column = unidecode(row['description'])\n",
      "        column = re.sub('  +', ' ', column)\n",
      "        column = re.sub('\\n', ' ', column)\n",
      "        column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
      "        \n",
      "        if column != \"\":\n",
      "            myString = \"\"\n",
      "            for x in cleanText(column):\n",
      "                myString += x + ' '\n",
      "            corpus += [dictionary.doc2bow(myString.split())]\n",
      "            \n",
      "    print corpus[-5:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[(5, 1), (31, 1), (162, 1), (172, 1), (399, 1), (435, 1), (902, 1), (1381, 1), (1400, 1), (1458, 1), (1588, 1), (2749, 1), (2752, 1)], [(5, 2), (25, 1), (39, 1), (66, 1), (139, 1), (142, 1), (152, 1), (194, 1), (197, 3), (253, 1), (274, 2), (996, 1), (1419, 1), (6141, 2)], [(247, 1), (276, 1), (454, 1), (1343, 1), (1906, 1), (2373, 1), (5312, 1), (6134, 1), (7214, 1), (7676, 1)], [(3, 1), (75, 1), (112, 1), (148, 1), (209, 1), (374, 1), (455, 1), (666, 1), (1109, 1), (1649, 2)], [(5, 1), (63, 1), (74, 1), (139, 1), (247, 1), (356, 3), (369, 1), (375, 1), (485, 1), (501, 1), (559, 1), (574, 1), (588, 1), (666, 2), (1089, 1)]]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:5: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpora.MmCorpus.serialize('corpus.mm', corpus) # Save corpus to disk\n",
      "corpus2 = corpora.MmCorpus('corpus.mm') # Load corpus\n",
      "print corpus2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MmCorpus(4283 documents, 7677 features, 92713 non-zero entries)\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}