{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from unidecode import unidecode\n",
      "import re\n",
      "\n",
      "from gensim import corpora\n",
      "from nltk.stem.porter import *\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.tokenize import WordPunctTokenizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up the infrastructure to clean the text\n",
      "stopset = set(stopwords.words('english'))\n",
      "stemmer = PorterStemmer()\n",
      "def cleanText(column):\n",
      "    tokens = WordPunctTokenizer().tokenize(column)\n",
      "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2]\n",
      "    final = [stemmer.stem(word) for word in clean]\n",
      "    return final"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Switch to our working directory and set up our input and out put paths,\n",
      "# as well as our settings and training file locations\n",
      "input_file = 'products.csv'\n",
      "\n",
      "# Set up the dictionary\n",
      "dictionary = corpora.Dictionary()\n",
      "\n",
      "with open(input_file) as f:\n",
      "    reader = csv.DictReader(f)\t\n",
      "    for row in reader:\n",
      "        column = unidecode(row['description'])\n",
      "        column = re.sub('  +', ' ', column)\n",
      "        column = re.sub('\\n', ' ', column)\n",
      "        column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
      "        \n",
      "        if column != \"\":\n",
      "            myString = \"\"\n",
      "            for x in cleanText(column):\n",
      "                myString += x + ' '\n",
      "            dictionary.add_documents([myString.split()])\n",
      "            \n",
      "dictionary.filter_extremes(no_below=2)\n",
      "dictionary.save('dictionary.mm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:11: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(6058 unique tokens: [u'yellow', u'interchang', u'four', u'autoformat', u'authorit']...)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(input_file) as f:\n",
      "    reader = csv.DictReader(f)\t\n",
      "    corpus = []\n",
      "    for row in reader:\n",
      "        column = unidecode(row['description'])\n",
      "        column = re.sub('  +', ' ', column)\n",
      "        column = re.sub('\\n', ' ', column)\n",
      "        column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
      "        \n",
      "        if column != \"\":\n",
      "            myString = \"\"\n",
      "            for x in cleanText(column):\n",
      "                myString += x + ' '\n",
      "            corpus += [dictionary.doc2bow(myString.split())]\n",
      "            \n",
      "    print corpus[-5:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[(263, 1), (956, 1), (1214, 1), (1921, 1), (2002, 1), (2159, 1), (2343, 1), (2518, 1), (2552, 1), (2710, 1), (2870, 1), (2897, 1), (3027, 1), (3141, 2), (3220, 1), (3283, 1), (4105, 1), (4134, 1), (4297, 1), (4457, 1), (4533, 1), (4870, 1), (4944, 2), (5435, 1), (5631, 1)], [(126, 1), (201, 1), (336, 1), (525, 1), (1065, 1), (1555, 1), (1655, 1), (1824, 1), (1919, 1), (1945, 1), (1966, 3), (2503, 1), (2518, 1), (2927, 1), (3006, 1), (3361, 1), (5320, 1), (5435, 2), (5622, 2), (5805, 2), (6050, 1)], [(14, 1), (686, 1), (1311, 1), (1533, 1), (1578, 1), (1608, 1), (1831, 1), (2410, 1), (2518, 1), (2521, 1), (2522, 1), (3007, 1), (3353, 1), (3574, 1), (3757, 1), (4327, 1), (4451, 1), (5069, 2), (5903, 1)], [(718, 1), (913, 1), (982, 2), (984, 1), (1278, 1), (1568, 2), (1918, 1), (2132, 1), (2466, 1), (2518, 1), (2822, 1), (3372, 2), (3760, 3), (3892, 1), (4116, 1), (4487, 2), (4496, 1), (4797, 1), (5805, 1), (5886, 2), (5998, 1)], [(7, 3), (161, 1), (345, 1), (686, 1), (1271, 1), (1781, 2), (1824, 1), (2319, 1), (2466, 3), (2518, 1), (2606, 1), (2628, 1), (2672, 1), (2743, 1), (3966, 2), (4496, 2), (4989, 1), (5077, 2), (5435, 1)]]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpora.MmCorpus.serialize('corpus.mm', corpus) # Save corpus to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MmCorpus(4283 documents, 6058 features, 146007 non-zero entries)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.models.tfidfmodel import TfidfModel\n",
      "\n",
      "# Create a TfIDF model\n",
      "if corpus is None:\n",
      "    corpus = corpora.MmCorpus('corpus.mm') # Load corpus\n",
      "    \n",
      "model_tfidf = TfidfModel(corpus, id2word=dictionary, normalize=True)\n",
      "\n",
      "model_tfidf.save('tfidf_model.mm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model_tfidf.num_docs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4283\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "str1 = 'hello world my name is Matt Henricks yellow'\n",
      "str2 = 'blanket time for all yellow'\n",
      "str1 = model_tfidf[dictionary.doc2bow(str1.split())]\n",
      "str2 = model_tfidf[dictionary.doc2bow(str2.split())]\n",
      "\n",
      "print str1, str2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 0.5580106662055712), (671, 0.24165083256456826), (1126, 0.728120491661595), (5006, 0.3163376694991332)] [(0, 0.9375682832768192), (381, 0.3478012567449378)]\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.similarities import MatrixSimilarity\n",
      "\n",
      "index = MatrixSimilarity([str1],num_features=len(dictionary))\n",
      "sim = index[str2]\n",
      "sim = index.get_similarities(str2)[0]\n",
      "print str(round(sim*100,2))+'% similar'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "52.32% similar\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.matutils import cossim\n",
      "\n",
      "print cossim(str1, str2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.523173102365\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_path = 'tfidf_model.mm'\n",
      "model = TfidfModel.load(model_path)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.num_docs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "4283"
       ]
      }
     ],
     "prompt_number": 51
    }
   ],
   "metadata": {}
  }
 ]
}